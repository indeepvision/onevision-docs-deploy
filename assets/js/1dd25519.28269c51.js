"use strict";(self.webpackChunk_indeepvision_onevision_docs=self.webpackChunk_indeepvision_onevision_docs||[]).push([[705],{876:(e,t,a)=>{a.d(t,{Zo:()=>p,kt:()=>d});var n=a(2784);function i(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function r(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function o(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?r(Object(a),!0).forEach((function(t){i(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):r(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function l(e,t){if(null==e)return{};var a,n,i=function(e,t){if(null==e)return{};var a,n,i={},r=Object.keys(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||(i[a]=e[a]);return i}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(i[a]=e[a])}return i}var s=n.createContext({}),c=function(e){var t=n.useContext(s),a=t;return e&&(a="function"==typeof e?e(t):o(o({},t),e)),a},p=function(e){var t=c(e.components);return n.createElement(s.Provider,{value:t},e.children)},m="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},g=n.forwardRef((function(e,t){var a=e.components,i=e.mdxType,r=e.originalType,s=e.parentName,p=l(e,["components","mdxType","originalType","parentName"]),m=c(a),g=i,d=m["".concat(s,".").concat(g)]||m[g]||u[g]||r;return a?n.createElement(d,o(o({ref:t},p),{},{components:a})):n.createElement(d,o({ref:t},p))}));function d(e,t){var a=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var r=a.length,o=new Array(r);o[0]=g;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l[m]="string"==typeof e?e:i,o[1]=l;for(var c=2;c<r;c++)o[c]=a[c];return n.createElement.apply(null,o)}return n.createElement.apply(null,a)}g.displayName="MDXCreateElement"},4662:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>s,contentTitle:()=>o,default:()=>u,frontMatter:()=>r,metadata:()=>l,toc:()=>c});var n=a(7896),i=(a(2784),a(876));const r={sidebar_position:5},o="Quickstart",l={unversionedId:"guide/quickstart",id:"guide/quickstart",title:"Quickstart",description:"Let's discover OneVision in less than 5 minutes.",source:"@site/docs/guide/5-quickstart.md",sourceDirName:"guide",slug:"/guide/quickstart",permalink:"/onevision/docs/guide/quickstart",draft:!1,tags:[],version:"current",sidebarPosition:5,frontMatter:{sidebar_position:5},sidebar:"guideSidebar",previous:{title:"Installation",permalink:"/onevision/docs/guide/installation"},next:{title:"Home",permalink:"/onevision/docs/guide/home"}},s={},c=[{value:"Layout of the application",id:"layout-of-the-application",level:2},{value:"Home",id:"home",level:3},{value:"MES",id:"mes",level:3},{value:"Project",id:"project",level:3},{value:"Configuration",id:"configuration",level:3},{value:"Application bar",id:"application-bar",level:3},{value:"Create a new project",id:"create-a-new-project",level:2},{value:"Add an emulation camera",id:"add-an-emulation-camera",level:2},{value:"Trigger the camera",id:"trigger-the-camera",level:2},{value:"Buttons for manual camera operation are:",id:"buttons-for-manual-camera-operation-are",level:4},{value:"Add a brain",id:"add-a-brain",level:2},{value:"Execute inference on a brain",id:"execute-inference-on-a-brain",level:2},{value:"Create a program sequence",id:"create-a-program-sequence",level:2},{value:"Run the program",id:"run-the-program",level:2}],p={toc:c},m="wrapper";function u(e){let{components:t,...r}=e;return(0,i.kt)(m,(0,n.Z)({},p,r,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("h1",{id:"quickstart"},"Quickstart"),(0,i.kt)("p",null,"Let's discover ",(0,i.kt)("strong",{parentName:"p"},"OneVision in less than 5 minutes"),"."),(0,i.kt)("h2",{id:"layout-of-the-application"},"Layout of the application"),(0,i.kt)("p",null,"When you open OneVision you will see the following layout. There are 4 main ",(0,i.kt)("strong",{parentName:"p"},"sections")," in the application:"),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Home layout",src:a(7812).Z,width:"935",height:"515"})),(0,i.kt)("h3",{id:"home"},"Home"),(0,i.kt)("p",null,"This is the production view, where the program results are shown, and also where you can manually trigger cameras and execute inference on AI models. This is what the application will show most of the time, as during production it is the most useful. ",(0,i.kt)("a",{parentName:"p",href:"/onevision/docs/guide/home"},"Read more.")),(0,i.kt)("h3",{id:"mes"},"MES"),(0,i.kt)("p",null,"This is an internal database where production images and results are stored. The information stored here can be queried for result analysis by vision engineers or quality personnel. The size of the database is automatically managed, removing oldest entries. ",(0,i.kt)("a",{parentName:"p",href:"/onevision/docs/guide/mes"},"Read more.")),(0,i.kt)("h3",{id:"project"},"Project"),(0,i.kt)("p",null,"In the project section you can define a collection of cameras, brains, runtime sequences and a visualization, specific to a particular use-case. Different project files can be stored and loaded when the product reference changes, or to experiment with different configurations. ",(0,i.kt)("a",{parentName:"p",href:"/onevision/docs/guide/project/project-files"},"Read more.")),(0,i.kt)("h3",{id:"configuration"},"Configuration"),(0,i.kt)("p",null,"The configuration determines the behavior of the application as a vision workstation within a factory. As such, it is static, different configurations cannot be loaded like a project. It includes the configuration of communication interfaces with the outside world, the configuration of the system signals, and the general settings of the software. ",(0,i.kt)("a",{parentName:"p",href:"/onevision/docs/guide/configuration/communications"},"Read more.")),(0,i.kt)("h3",{id:"application-bar"},"Application bar"),(0,i.kt)("p",null,"This is the top blue bar of the application, which is always visible. It contains the following elements:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"Project:")," this is where you can create a new project, open an existing project, save the current project, etc."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"Help:")," this is where you can find the documentation, license manager, etc."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"Current opened project:")," this is where you can see the name of the current opened project."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"Application buttons:")," standard buttons to minimize, maximize and close the application. The close button ",(0,i.kt)("strong",{parentName:"li"},"only hides")," the application, it does not close it.")),(0,i.kt)("admonition",{type:"tip"},(0,i.kt)("p",{parentName:"admonition"},"To close the application you must use the ",(0,i.kt)("strong",{parentName:"p"},"Exit")," button in the ",(0,i.kt)("strong",{parentName:"p"},"Project")," menu in the topbar.")),(0,i.kt)("h2",{id:"create-a-new-project"},"Create a new project"),(0,i.kt)("p",null,"We will start by ",(0,i.kt)("strong",{parentName:"p"},"creating a new project"),". Click on the ",(0,i.kt)("strong",{parentName:"p"},"Project")," menu in the top bar and then click on ",(0,i.kt)("strong",{parentName:"p"},"New Project"),"."),(0,i.kt)("p",null,"A popup will show where you can enter the name of your project (for example ",(0,i.kt)("inlineCode",{parentName:"p"},"quickstart_ov"),"), author (you or your company) and a description (optional)."),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Create project popup",src:a(3144).Z,width:"328",height:"203"})),(0,i.kt)("p",null,"Once you have created the project, the name of the project will appear in the top bar."),(0,i.kt)("p",null,"Go to the ",(0,i.kt)("strong",{parentName:"p"},"Project")," section in the left menu, you will see we have created an empty project."),(0,i.kt)("p",null,"Now let's start adding some elements to the project."),(0,i.kt)("h2",{id:"add-an-emulation-camera"},"Add an emulation camera"),(0,i.kt)("p",null,"From the ",(0,i.kt)("strong",{parentName:"p"},"Project")," section, click on ",(0,i.kt)("strong",{parentName:"p"},"Cameras"),". Here is where all the cameras used by the application must be added. Each camera will appear as a separate tab."),(0,i.kt)("p",null,"To add an ",(0,i.kt)("strong",{parentName:"p"},"Emulation")," camera click on the add button ",(0,i.kt)("img",{alt:"Add button",src:a(777).Z,width:"14",height:"14"})," in the top left corner."),(0,i.kt)("p",null,"A popup will appear where you can enter the name of the camera (for example ",(0,i.kt)("inlineCode",{parentName:"p"},"emulation_cam"),"),"),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Add camera popup",src:a(4967).Z,width:"320",height:"254"})),(0,i.kt)("p",null,"Now you can try to save the changes clicking on ",(0,i.kt)("strong",{parentName:"p"},"Save")," in the left menu. This will save the current changes to the project file. Click ",(0,i.kt)("strong",{parentName:"p"},"Discard changes")," if you want to discard the changes made to the project."),(0,i.kt)("p",null,"After saving, the emulation camera status will change from ",(0,i.kt)("strong",{parentName:"p"},"Not initialized")," to ",(0,i.kt)("strong",{parentName:"p"},"Configuration error"),". This is because we have not yet configured the camera, primarily we have not introduced a serial number."),(0,i.kt)("p",null,"Because emulation cameras are an internal feature of OneVision, the developers have defined 8 possible serial number for emulation cameras. For the moment we will use the first emulation camera, so enter ",(0,i.kt)("strong",{parentName:"p"},"EMU1")," in the ",(0,i.kt)("strong",{parentName:"p"},"Camera serial")," field on the ",(0,i.kt)("strong",{parentName:"p"},"Device selection")," section."),(0,i.kt)("p",null,"Now click on ",(0,i.kt)("strong",{parentName:"p"},"Save")," in the left menu, the emulation camera status will change to ",(0,i.kt)("strong",{parentName:"p"},"Connected"),"."),(0,i.kt)("h2",{id:"trigger-the-camera"},"Trigger the camera"),(0,i.kt)("p",null,"If you go to the ",(0,i.kt)("strong",{parentName:"p"},"Home")," section you will be able to manually trigger the camera and see the images captured by it."),(0,i.kt)("p",null,"If you click on ",(0,i.kt)("strong",{parentName:"p"},"Single shot")," you will force the capture of an image by the camera. By default, the images generated by Emulation cameras are 1920 x 1080 monochrome images, with a moving diagonal pattern."),(0,i.kt)("h4",{id:"buttons-for-manual-camera-operation-are"},"Buttons for manual camera operation are:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"Single shot"),": Force the capture of a single image by the camera."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"Start video"),": Force the start of a video stream from the camera (normally limited to 15 fps)."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"Start acquisition"),": Start the normal acquisition of images from the camera."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"Software trigger"),": Only enabled if the camera is in acquisition mode. Sends a software trigger to the the camera if it supports it."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"Switch camera"),": Switch between different cameras in the project (we have for the moment a single camera).")),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Manual camera operation",src:a(2292).Z,width:"1344",height:"805"})),(0,i.kt)("h2",{id:"add-a-brain"},"Add a brain"),(0,i.kt)("p",null,"The AI models or ",(0,i.kt)("strong",{parentName:"p"},(0,i.kt)("em",{parentName:"strong"},"brains"))," allow us to execute analysis based on Artificial Intelligence. Let's add a new brain to the project."),(0,i.kt)("p",null,"From the ",(0,i.kt)("strong",{parentName:"p"},"Project")," section, click on ",(0,i.kt)("strong",{parentName:"p"},"Brains"),". Here is where all the brains used by the application must be added. Each brain will appear as a separate tab."),(0,i.kt)("p",null,"To add a ",(0,i.kt)("strong",{parentName:"p"},"Brain")," click on the add button ",(0,i.kt)("img",{alt:"Add button",src:a(777).Z,width:"14",height:"14"})," in the top left corner."),(0,i.kt)("p",null,"A popup will appear where you can enter the name of the brain (for example ",(0,i.kt)("inlineCode",{parentName:"p"},"test_brain"),"). Once added, two different screens will show for the brain, the ",(0,i.kt)("strong",{parentName:"p"},"Model selection")," screen is where you can select the AI model to use for the brain, and the ",(0,i.kt)("strong",{parentName:"p"},"Configuration")," screen is where you can configure different parameters for the brain, such as if inference will run on GPU or CPU."),(0,i.kt)("p",null,"We need to import an AI model before assigning it to the brain. From the ",(0,i.kt)("strong",{parentName:"p"},"Model selection")," screen, click on the add button ",(0,i.kt)("img",{alt:"Add button",src:a(777).Z,width:"14",height:"14"})," in the bottom of the empty table. Select a model file from your computer and click on ",(0,i.kt)("strong",{parentName:"p"},"Open"),". The imported file must have the extension ",(0,i.kt)("inlineCode",{parentName:"p"},".brain"),"."),(0,i.kt)("p",null,"In the example we have added a model called ",(0,i.kt)("strong",{parentName:"p"},(0,i.kt)("em",{parentName:"strong"},"dry_fruit_sample"))," with version number 2."),(0,i.kt)("p",null,"Now select assign the model to the brain by clicking on the ",(0,i.kt)("strong",{parentName:"p"},"Select")," button. Save the changes made to the project and you will see how the brain status changes from ",(0,i.kt)("strong",{parentName:"p"},"Not initialized")," to ",(0,i.kt)("strong",{parentName:"p"},"Ready"),"."),(0,i.kt)("p",null,"If no model is selected, the brain status will be ",(0,i.kt)("strong",{parentName:"p"},"Initialization error"),"."),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"AI model selection",src:a(9513).Z,width:"1344",height:"805"})),(0,i.kt)("h2",{id:"execute-inference-on-a-brain"},"Execute inference on a brain"),(0,i.kt)("p",null,"Let's move back to the ",(0,i.kt)("strong",{parentName:"p"},"Home")," section and see how the brain works. Click on the ",(0,i.kt)("strong",{parentName:"p"},"Single shot")," button to capture an image from the emulation camera. The brains now will be enabled, click on ",(0,i.kt)("strong",{parentName:"p"},"Inference")," to execute a manual inference on the image just captured."),(0,i.kt)("p",null,"Because the brain is not supposed to work on the image captured by the camera, the inference result will be a very low probability segmentation. You can see the ",(0,i.kt)("strong",{parentName:"p"},"objects added by the inference")," on the ",(0,i.kt)("strong",{parentName:"p"},"Objects")," right-side panel. In this case we have 5 results: almonds, hazlenuts, peanuts, pistachios and raisins."),(0,i.kt)("p",null,"We will now open an image from disk with dry fruits. Click on ",(0,i.kt)("strong",{parentName:"p"},"Open image")," and select the image ",(0,i.kt)("inlineCode",{parentName:"p"},"dry_fruits_001.jpg"),". Now execute inference again and you will see how the results are much better."),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Inference results",src:a(9909).Z,width:"1344",height:"805"})),(0,i.kt)("h2",{id:"create-a-program-sequence"},"Create a program sequence"),(0,i.kt)("p",null,"Let's start writing some code. We want to create a program that opens images from a folder and executes our brain on them. To do this we will create a ",(0,i.kt)("strong",{parentName:"p"},"program sequence"),"."),(0,i.kt)("p",null,"Go to the ",(0,i.kt)("strong",{parentName:"p"},"Project")," section and then click on ",(0,i.kt)("strong",{parentName:"p"},"Programming"),". In the ",(0,i.kt)("strong",{parentName:"p"},"Sequences")," screen, click on the add button ",(0,i.kt)("img",{alt:"Add button",src:a(777).Z,width:"14",height:"14"})," in the top left corner. This will open a new sequence popup, where you can enter the name of the sequence (for example ",(0,i.kt)("inlineCode",{parentName:"p"},"test_sequence"),") and also select the ",(0,i.kt)("strong",{parentName:"p"},"type of sequence"),", in this case we will select ",(0,i.kt)("strong",{parentName:"p"},"SIMPLE"),"."),(0,i.kt)("admonition",{type:"tip"},(0,i.kt)("p",{parentName:"admonition"},(0,i.kt)("strong",{parentName:"p"},"Sequence types")),(0,i.kt)("ul",{parentName:"admonition"},(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"SIMPLE:")," It is executed once when the program starts and then it is finished."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"CYCLIC:")," It is executed continuously, once finished it is executed again."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"INIT:")," It is executed once when the program starts, before any other sequence execute."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"END:")," It is executed once when the program is stopped, after other sequences have ended."))),(0,i.kt)("p",null,"Now add the following lines of code:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-javascript",metastring:'title="Quickstart runtime sequence"',title:'"Quickstart',runtime:!0,'sequence"':!0},'\n// OneVision quickstart program\n\n// Configure location of the images\nconst var IMAGES_FOLDER = "C:\\dry_fruits_images\\";\n\n// List the images in the folder\nvar images_list = File.listImagesFromDir(IMAGES_FOLDER);\n\nfor (var i = 0; i < images_list.length; i++) {\n    // Create the complete path to the image\n    var image_filepath = IMAGES_FOLDER + images_list[i];\n\n    // Load the image into an Image vision element\n    var loaded_image = Image.fromEncodedFile(image_filepath);\n\n    // Resize the image to match the input size\n    loaded_image = loaded_image.resize(1224, 1024);\n\n    // Execute inference on the image\n    var inference_result = Brains.test_brain.inference(loaded_image);\n\n    // Change the color of the segmentations\n    inference_result.almonds.setColor("#ff0000");\n    inference_result.hazelnuts.setColor("#00ff00");\n    inference_result.peanuts.setColor("#0000ff");\n    inference_result.pistachios.setColor("#00ffff");\n    inference_result.raisins.setColor("#ff00ff");\n\n    // Create a capture to send to the GUI\n    var capture = new Capture("Dry fruits", loaded_image);\n    capture.addVisionElement("almonds", inference_result.almonds);\n    capture.addVisionElement("hazelnuts", inference_result.hazelnuts);\n    capture.addVisionElement("peanuts", inference_result.peanuts);\n    capture.addVisionElement("pistachios", inference_result.pistachios);\n    capture.addVisionElement("raisins", inference_result.raisins);\n\n    // Send the capture\n    Visu.display.sendCapture(capture);\n    Visu.update();\n\n    // Wait some time\n    waitTime(1000);\n}\n')),(0,i.kt)("p",null,"This code will open the images in the configured folder and execute inference on them."),(0,i.kt)("p",null,"Save the changes made to the project by clicking on ",(0,i.kt)("strong",{parentName:"p"},"Save")," in the left menu."),(0,i.kt)("h2",{id:"run-the-program"},"Run the program"),(0,i.kt)("p",null,"The program (or runtime) is executed in the ",(0,i.kt)("strong",{parentName:"p"},"Home")," section. Click on ",(0,i.kt)("strong",{parentName:"p"},"Start program")," to start the program. You will see how the images are opened and inference is executed on them. For each image a new capture is shown in the GUI."),(0,i.kt)("p",null,"After all the images have been processed and the ",(0,i.kt)("inlineCode",{parentName:"p"},"for")," loop is finished, the program will stop automatically."),(0,i.kt)("p",null,"You can also stop the program manually by clicking on ",(0,i.kt)("strong",{parentName:"p"},"Stop program"),"."),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Test program results",src:a(8846).Z,width:"1344",height:"805"})))}u.isMDXComponent=!0},777:(e,t,a)=>{a.d(t,{Z:()=>n});const n="data:image/svg+xml;base64,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"},4967:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/add_camera_popup_70-e14916f82dade65c583bfed560827e9e.png"},9513:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/brain_model_selection_70-dc9ea77135fe90704fb5c02a2cc1177c.png"},3144:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/create_project_popup_70-e03c1b83fb34b41d0615f74a8ead623c.png"},7812:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/layout_home_70-de825697d75a9ed504637f0a5633c750.PNG"},9909:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/manual_brain_operation_70-9b81bb100b9c2630eed52c9eb5566adc.png"},2292:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/manual_camera_operation_70-ff0e3e83c30ba10f12e8ee79833fa5ea.png"},8846:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/quickstart_program_capture_70-62080b2c75e955eef1392f5f79e7102b.png"}}]);